{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02efd5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import utils,preprocessing,feature_extraction,feature_selection, model_selection, naive_bayes, pipeline, manifold, preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "from keras import models,layers\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import nltk\n",
    "import re\n",
    "import transformers\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a9d2278",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcol='title'\n",
    "#fcol='text'\n",
    "def cleanText(text):\n",
    "    text = BeautifulSoup(text, \"lxml\").text\n",
    "    text = re.sub(r'\\|\\|\\|', r' ', text) \n",
    "    text = re.sub(r'http\\S+', r'<URL>', text)\n",
    "    text = text.lower()\n",
    "    text = text.replace('x', '')\n",
    "    return text\n",
    "\n",
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words)) for doc in sents])\n",
    "    return targets, regressors\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens\n",
    "\n",
    "def runDoc2Vec(train,test,epochs):\n",
    "    gtraintagged=train.apply(lambda r: TaggedDocument (words=tokenize_text(r[fcol]),\n",
    "                                                          tags=[r.Label]),axis=1)\n",
    "    gtesttagged=test.apply(lambda r: TaggedDocument (words=tokenize_text(r[fcol]),\n",
    "                                                        tags=[r.Label]),axis=1)\n",
    "    cores = multiprocessing.cpu_count()\n",
    "    #dbow\n",
    "    model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "    model_dbow.build_vocab([x for x in tqdm(gtraintagged.values)])\n",
    "    for epoch in range(epochs):\n",
    "        model_dbow.train(utils.shuffle([x for x in tqdm(gtraintagged.values)]), total_examples=len(gtraintagged.values), epochs=1)\n",
    "        model_dbow.alpha -= 0.002\n",
    "        model_dbow.min_alpha = model_dbow.alpha\n",
    "    y_train, X_train = vec_for_learning(model_dbow, gtraintagged)\n",
    "    y_test_dbow, X_test = vec_for_learning(model_dbow, gtesttagged)\n",
    "    pipedbow=make_pipeline(StandardScaler(), LogisticRegression(n_jobs=1, C=1e5))\n",
    "    pipedbow.fit(X_train, y_train)\n",
    "    y_pred_dbow = pipedbow.predict(X_test)\n",
    "    #dm\n",
    "    model_dmm=Doc2Vec(dm=1, dm_mean=1, vector_size=300, window=10, negative=5, min_count=1, workers=5, alpha=0.065, min_alpha=0.065)\n",
    "    model_dmm.build_vocab([x for x in tqdm(gtraintagged.values)])\n",
    "    for epoch in range(epochs):\n",
    "        model_dmm.train(utils.shuffle([x for x in tqdm(gtraintagged.values)]), total_examples=len(gtraintagged.values), epochs=1);\n",
    "        model_dmm.alpha -= 0.002\n",
    "        model_dmm.min_alpha = model_dmm.alpha\n",
    "    y_train, X_train = vec_for_learning(model_dbow, gtraintagged)\n",
    "    y_test_dm, X_test = vec_for_learning(model_dbow, gtesttagged)\n",
    "    pipedbow=make_pipeline(StandardScaler(), LogisticRegression(n_jobs=1, C=1e5))\n",
    "    pipedbow.fit(X_train, y_train)\n",
    "    y_pred_dm = pipedbow.predict(X_test)\n",
    "    #combined\n",
    "    #model_dbow.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "    #model_dmm.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "    new_model = ConcatenatedDoc2Vec([model_dbow, model_dmm])\n",
    "    y_train, X_train = vec_for_learning(new_model, gtraintagged)\n",
    "    y_test_combined, X_test = vec_for_learning(new_model, gtesttagged)\n",
    "    pipecomb=make_pipeline(StandardScaler(), LogisticRegression(n_jobs=1, C=1e5))\n",
    "    pipecomb.fit(X_train, y_train)\n",
    "    y_pred_combined = pipecomb.predict(X_test)\n",
    "    return {\n",
    "        'Accuracy Doc2Vec(DBOW)': accuracy_score(y_test_dbow, y_pred_dbow),\n",
    "        'F1 Doc2Vec(DBOW)': f1_score(y_test_dbow, y_pred_dbow, average='weighted'),\n",
    "        'Accuracy Doc2Vec(DM)': accuracy_score(y_test_dm, y_pred_dm),\n",
    "        'F1 Doc2Vec(DM)': f1_score(y_test_dm, y_pred_dm, average='weighted'),\n",
    "        'Accuracy Doc2Vec(Combined)': accuracy_score(y_test_combined, y_pred_combined),\n",
    "        'F1 Doc2Vec(Combined)':f1_score(y_test_combined, y_pred_combined, average='weighted')}\n",
    "\n",
    "def runtfidf(train,test):\n",
    "    vectorizer = feature_extraction.text.TfidfVectorizer(max_features=10000,ngram_range=(1,2))\n",
    "    corpus = train[fcol]\n",
    "    vectorizer.fit(corpus)\n",
    "    X_train = vectorizer.transform(corpus)\n",
    "    dic_vocabulary = vectorizer.vocabulary_\n",
    "    y = train[\"Label\"]\n",
    "    X_names = vectorizer.get_feature_names()\n",
    "    p_value_limit = 0.95\n",
    "    dtf_features = pd.DataFrame()\n",
    "    for cat in np.unique(y):\n",
    "        chi2, p = feature_selection.chi2(X_train, y==cat)\n",
    "        dtf_features = dtf_features.append(pd.DataFrame({\"feature\":X_names, \"score\":1-p, \"y\":cat}))\n",
    "        dtf_features = dtf_features.sort_values([\"y\",\"score\"],ascending=[True,False])\n",
    "        dtf_features = dtf_features[dtf_features[\"score\"]>p_value_limit]\n",
    "    X_names = dtf_features[\"feature\"].unique().tolist()\n",
    "    cf=LogisticRegression(n_jobs=1,C=1e5)\n",
    "    pipe=pipeline.Pipeline([('vectorizer',vectorizer),('classifier',cf)])\n",
    "    pipe['classifier'].fit(X_train,y.values)\n",
    "    X_test=test[fcol].values\n",
    "    y_test=test['Label'].values\n",
    "    pred=pipe.predict(X_test)\n",
    "    return {'Accuracy Tf-Idf':accuracy_score(y_test,pred),'F1 Tf-Idf':f1_score(y_test,pred)}\n",
    "\n",
    "def runbow(train,test):\n",
    "    vectorizer = feature_extraction.text.CountVectorizer(max_features=10000,ngram_range=(1,2))\n",
    "    corpus = train[fcol]\n",
    "    vectorizer.fit(corpus)\n",
    "    X_train = vectorizer.transform(corpus)\n",
    "    dic_vocabulary = vectorizer.vocabulary_\n",
    "    y = train[\"Label\"]\n",
    "    X_names = vectorizer.get_feature_names()\n",
    "    p_value_limit = 0.95\n",
    "    dtf_features = pd.DataFrame()\n",
    "    for cat in np.unique(y):\n",
    "        chi2, p = feature_selection.chi2(X_train, y==cat)\n",
    "        dtf_features = dtf_features.append(pd.DataFrame({\"feature\":X_names, \"score\":1-p, \"y\":cat}))\n",
    "        dtf_features = dtf_features.sort_values([\"y\",\"score\"],ascending=[True,False])\n",
    "        dtf_features = dtf_features[dtf_features[\"score\"]>p_value_limit]\n",
    "    X_names = dtf_features[\"feature\"].unique().tolist()\n",
    "    cf=LogisticRegression(n_jobs=1,C=1e5)\n",
    "    pipe=pipeline.Pipeline([('vectorizer',vectorizer),('classifier',cf)])\n",
    "    pipe['classifier'].fit(X_train,y.values)\n",
    "    X_test=test[fcol].values\n",
    "    y_test=test['Label'].values\n",
    "    pred=pipe.predict(X_test)\n",
    "    return {'Accuracy BOW':accuracy_score(y_test,pred),'F1 BOW':f1_score(y_test,pred)}\n",
    "\n",
    "def runBERT2(data):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[fcol],data['Label'],test_size=0.2,random_state=14,stratify=data['Label'].values)\n",
    "    bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "    bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessed_text = bert_preprocess(text_input)\n",
    "    outputs = bert_encoder(preprocessed_text)\n",
    "    l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "    l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
    "    model = tf.keras.Model(inputs=[text_input], outputs = [l])\n",
    "    METRICS = [tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    "    model.compile(optimizer='adam',\n",
    "     loss='binary_crossentropy',\n",
    "     metrics=METRICS)\n",
    "    model.fit(X_train,y_train,epochs=30)\n",
    "    y_pred=model.predict(X_test)\n",
    "    y_pred=y_pred.flatten()\n",
    "    pred = np.where(y_pred > 0.5, 1, 0)\n",
    "    return {'Accuracy BERT':accuracy_score(y_test,pred),'F1 BERT':f1_score(y_test,pred)}\n",
    "\n",
    "def runGloVe(data):\n",
    "    #pre-process\n",
    "    data[fcol]=data[fcol].apply(lambda x: x.lower())\n",
    "    #tokenizer\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "    tokenizer.fit_on_texts(data[fcol].values)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    X = tokenizer.texts_to_sequences(data[fcol].values)\n",
    "    #padding\n",
    "    X = tf.keras.preprocessing.sequence.pad_sequences(X,maxlen = 1000, padding = 'post')\n",
    "    #create train and test sets\n",
    "    y=pd.get_dummies(data['Label']).values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=14,stratify=y)\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_test.shape)\n",
    "    #load embeddings\n",
    "    embeddings_index = dict()\n",
    "    f = open('./dataset/glove.6B.200d.txt',encoding=\"utf8\")\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    #create embedding matrix\n",
    "    embedding_matrix = np.zeros((vocab_size, 200))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    #model\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(Embedding(vocab_size, 200, weights=[embedding_matrix], input_length=1000, trainable=False))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    # compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "    y_pred=model.predict(X_test)\n",
    "    #y_pred=y_pred.flatten()\n",
    "    pred = np.where(y_pred > 0.5, True, False)\n",
    "    return {'Accuracy GloVe':accuracy_score(y_test,pred),'F1 GloVe':f1_score(y_test,pred,pos_label=True,average='weighted')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b43f3937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18948\n",
      "59484\n",
      "1488\n",
      "1820\n"
     ]
    }
   ],
   "source": [
    "#initialize datasets\n",
    "\n",
    "#nltk.download(\"popular\")\n",
    "file_cols=['id','title','text']\n",
    "gossipli=[]\n",
    "gossipli.append(pd.read_csv('./dataset/gossipcop_fake.csv',index_col=None,usecols=file_cols).assign(Label=False))\n",
    "gossipli.append(pd.read_csv('./dataset/gossipcop_real.csv',index_col=None,usecols=file_cols).assign(Label=True))\n",
    "gossip=pd.concat(gossipli,axis=0,ignore_index=True)\n",
    "politili=[]\n",
    "politili.append(pd.read_csv('./dataset/politifact_fake.csv',index_col=None,usecols=file_cols).assign(Label=False))\n",
    "politili.append(pd.read_csv('./dataset/politifact_real.csv',index_col=None,usecols=file_cols).assign(Label=True))\n",
    "politi=pd.concat(politili,axis=0,ignore_index=True)\n",
    "print(gossip[gossip[\"Label\"]==False].size)\n",
    "print(gossip[gossip[\"Label\"]==True].size)\n",
    "print(politi[politi[\"Label\"]==False].size)\n",
    "print(politi[politi[\"Label\"]==True].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f860277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset\n",
    "gossip[fcol]=gossip[fcol].apply(cleanText)\n",
    "politi[fcol]=politi[fcol].apply(cleanText)\n",
    "gossip_train, gossip_test =train_test_split(gossip,test_size=0.2,random_state=14,stratify=gossip['Label'].values)\n",
    "politi_train, politi_test =train_test_split(politi,test_size=0.2,random_state=14,stratify=politi['Label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72143e8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Th3o0\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Th3o0\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922719.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3487323.89it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3919681.41it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921316.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3923421.35it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921083.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922251.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3923421.35it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 4484177.52it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 4482039.14it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3920615.73it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3137726.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921784.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3138624.78it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921316.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3485476.40it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921784.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2614418.94it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921316.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 4482649.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 1081658.08it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921550.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3483815.33it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921083.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3920615.73it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 1205950.81it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3924123.38it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922485.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3920382.11it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 1306638.32it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921784.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922018.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921316.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921550.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 1157716.18it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3920615.73it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3919681.41it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3486399.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922719.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3486215.16it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3486399.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921316.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 4483260.82it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922719.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 1252677.07it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3486584.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921316.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921784.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922485.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3926465.30it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3923421.35it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2412166.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3924825.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 4482344.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3924123.38it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921550.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921316.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922018.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921784.25it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922251.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3486399.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3920615.73it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922719.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921316.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921083.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3484922.54it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2412343.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3920148.52it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3489728.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3486584.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3487508.75it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3924357.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921550.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3923187.39it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 4481733.82it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921316.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921784.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2613484.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921316.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2614211.17it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3486954.24it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921550.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921083.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3137277.79it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2853072.53it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 4482649.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3486215.16it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3485291.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922251.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3485476.40it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922018.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921784.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 1568227.60it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921550.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921316.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921083.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3486030.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922485.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921083.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921316.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3485476.40it/s]\n",
      "C:\\Users\\Th3o0\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3137726.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3486215.16it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3136829.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3923187.39it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922953.46it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921083.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3920615.73it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3923421.35it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 1567741.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 1077742.24it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921316.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3485845.74it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 1206370.95it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921316.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922719.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922251.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3919914.95it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3923889.34it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922251.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921784.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922018.04it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922251.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3924357.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921550.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3136978.62it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921784.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3486399.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921550.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921550.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3918980.97it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3486030.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922251.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922953.46it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3924123.38it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 1254277.13it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922251.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922018.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922018.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3485845.74it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3486030.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922018.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922018.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922018.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3923889.34it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3486954.24it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3136380.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3483261.99it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 4482039.14it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3486769.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921784.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922953.46it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921784.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3918280.78it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921550.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921316.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3485661.06it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922485.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3919447.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3486215.16it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921784.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922018.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922251.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3924357.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3922251.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921550.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3919214.42it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3921550.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3919681.41it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3486030.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2614626.74it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 1654641.43it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3923889.34it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2850847.24it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2851465.03it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2852577.72it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3136081.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2852206.73it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2613069.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2851465.03it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 1845545.53it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 1960775.24it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2852454.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2851959.45it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2850476.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 3136829.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2614107.30it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2615250.33it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2851959.45it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2851341.45it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2240637.96it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 1568414.53it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2852206.73it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2852948.81it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2851712.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2852577.72it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2854062.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2852330.38it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2852206.73it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2851712.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2091352.32it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 15686/15686 [00:00<00:00, 2240485.36it/s]\n",
      "C:\\Users\\Th3o0\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Th3o0\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15686, 1000)\n",
      "(3922, 1000)\n",
      "(15686, 2)\n",
      "(3922, 2)\n",
      "Epoch 1/30\n",
      "491/491 [==============================] - 1908s 4s/step - loss: 0.5477 - accuracy: 0.7553\n",
      "Epoch 2/30\n",
      "187/491 [==========>...................] - ETA: 20:34 - loss: 0.5215 - accuracy: 0.7660"
     ]
    }
   ],
   "source": [
    "#runs gossipcop\n",
    "\n",
    "gtfidfres=runtfidf(gossip_train,gossip_test)\n",
    "gbowres=runbow(gossip_train,gossip_test)\n",
    "gdoc2vecres=runDoc2Vec(gossip_train,gossip_test,100)\n",
    "ggloveres=runGloVe(gossip)\n",
    "gBERTres=runBERT2(gossip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a3ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#runs politifact\n",
    "\n",
    "ptfidfres=runtfidf(politi_train,politi_test)\n",
    "pbowres=runbow(politi_train,politi_test)\n",
    "pdoc2vecres=runDoc2Vec(politi_train,politi_test,100)\n",
    "pgloveres=runGloVe(politi)\n",
    "pBERTres=runBERT2(politi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7718df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##print Gossipcop results\n",
    "print('----------=================Gossip Results==================----------------')\n",
    "print('Results for Tf-Idf ',gtfidfres)\n",
    "print('Results for BOW ',gbowres)\n",
    "print('Results for Doc2Vec ',gdoc2vecres)\n",
    "print('Results for GloVe',ggloveres)\n",
    "print('Results for BERT ',gBERTres)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cded2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##print Gossipcop results\n",
    "print('----------=================Politi Results==================----------------')\n",
    "print('Results for Tf-Idf ',ptfidfres)\n",
    "print('Results for BOW ',pbowres)\n",
    "print('Results for Doc2Vec ',pdoc2vecres)\n",
    "print('Results for Glove ',pgloveres)\n",
    "print('Results for BERT ',pBERTres)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
